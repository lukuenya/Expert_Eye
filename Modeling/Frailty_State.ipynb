{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "from custom_functions import processing\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import statistics\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 299)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_excel('P:\\DATA_OCT_22\\Expert_Eye\\Dataset\\Data\\data_v11.xlsx')\n",
    "dataset = dataset.drop(['Foldername'], axis=1)\n",
    "\n",
    "dataset.shape\n",
    "\n",
    "#dataset = pd.read_excel('gait_posture.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_13452\\1262521951.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dataset.columns = dataset.columns.str.replace('[', '_')\n",
      "C:\\Users\\matth\\AppData\\Local\\Temp\\ipykernel_13452\\1262521951.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  dataset.columns = dataset.columns.str.replace(']', '_')\n"
     ]
    }
   ],
   "source": [
    "# Replace '[' , ']' , '<' and '>' with '_' in column names\n",
    "dataset.columns = dataset.columns.str.replace('[', '_')\n",
    "dataset.columns = dataset.columns.str.replace(']', '_')\n",
    "dataset.columns = dataset.columns.str.replace('<', '_')\n",
    "dataset.columns = dataset.columns.str.replace('>', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with > 50% missing values\n",
    "dataset = dataset.dropna(thresh=0.5*len(dataset), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = dataset.drop(['Fried_State',\n",
    "                              'Fried_Score',\n",
    "                              'Frailty_State','Frailty_Score'], axis=1).columns\n",
    "\n",
    "# Features\n",
    "X = dataset.drop(['Fried_State',\n",
    "                  'Fried_Score',\n",
    "                  'Frailty_State', 'Frailty_Score'], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = dataset['Frailty_State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for categorical variables in the dataset\n",
    "X_object_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "# Declare the columns as categorical for XGBoost\n",
    "for col in X_object_cols:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mp:\\DATA_OCT_22\\Expert_Eye\\Modeling\\Frailty_State.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Grid search for XGBoost\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mxgb_model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                            param_grid\u001b[39m=\u001b[39mparam_grid,\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                            scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mroc_auc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                            cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                            n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                            verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Calculate metrics\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X25sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m y_pred_proba \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mpredict_proba(X_test)[:, \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matth\\Anaconda3\\envs\\sklearn-env\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\matth\\Anaconda3\\envs\\sklearn-env\\Lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "best_overall_score = float('-inf')\n",
    "roc_auc_scores = []\n",
    "tpr_list = []\n",
    "feature_importances = []\n",
    "\n",
    "# Configure the StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# XGBoost model setup\n",
    "xgb_model = xgb.XGBClassifier(enable_categorical=True, random_state=42)\n",
    "\n",
    "# Parameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'tree_method': ['hist', 'approx'],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [7, 8, 10, 12],\n",
    "    'scale_pos_weight': [2.4],\n",
    "    'min_child_weight': [4, 6]\n",
    "}\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Grid search for XGBoost\n",
    "    grid_search = GridSearchCV(estimator=xgb_model,\n",
    "                               param_grid=param_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv=5,\n",
    "                               n_jobs=-1,\n",
    "                               verbose=0)\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate metrics\n",
    "    y_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    current_best_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Update the best model if the current one is better\n",
    "    if current_best_score > best_overall_score:\n",
    "        best_overall_score = current_best_score\n",
    "        best_overall_model = grid_search.best_estimator_\n",
    "\n",
    "    # Store the Roc Auc score for this fold\n",
    "    roc_auc_scores.append(current_best_score)\n",
    "\n",
    "    # Update TPR list for the model\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    tpr_list.append(np.interp(np.linspace(0, 1, 100), fpr, tpr))\n",
    "\n",
    "    # If the model has feature importances, store them\n",
    "    if hasattr(grid_search.best_estimator_, 'feature_importances_'):\n",
    "        feature_importances.append(grid_search.best_estimator_.feature_importances_)\n",
    "\n",
    "# Calculate average ROC AUC across folds\n",
    "avg_roc_auc = np.mean(roc_auc_scores)\n",
    "std_roc_auc = np.std(roc_auc_scores, ddof=1)\n",
    "\n",
    "# Print average and std ROC AUC\n",
    "print(f\"Model: XGBoost, Average ROC AUC: {avg_roc_auc}, Std: {std_roc_auc}\")\n",
    "\n",
    "# Best overall model information\n",
    "print(\"Best overall model:\", best_overall_model)\n",
    "print(\"Best overall ROC AUC:\", best_overall_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mp:\\DATA_OCT_22\\Expert_Eye\\Modeling\\Frailty_State.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# ... continuing from the previous code\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Calculate average TPR over all folds and plot ROC Curve\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m], linestyle\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/DATA_OCT_22/Expert_Eye/Modeling/Frailty_State.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m mean_tpr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(tpr_list), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate average TPR over all folds and plot ROC Curve\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8)\n",
    "\n",
    "mean_tpr = np.mean(np.array(tpr_list), axis=0)\n",
    "mean_tpr[-1] = 1.0  # ensure the curve ends at 1\n",
    "mean_auc = np.trapz(mean_tpr, np.linspace(0, 1, 100))\n",
    "plt.plot(np.linspace(0, 1, 100), mean_tpr, label=f\"XGBoost (AUC = {mean_auc:.2f})\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    " # Confusion matrix for all the data\n",
    "cm_overall = confusion_matrix(y, best_overall_model.predict(X))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(cm_overall, annot=True, fmt='g', cmap='Blues', square=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Best Model on Entire Dataset')\n",
    "plt.show()\n",
    "\n",
    "# Calculate average feature importances and plot them\n",
    "avg_importance = np.mean(feature_importances, axis=0)\n",
    "sorted_idx = np.argsort(avg_importance)[::-1][:10]  # top 10 features\n",
    "\n",
    "# Assuming feature_names is an array-like object with the feature names\n",
    "# Replace 'feature_names' with your actual feature names\n",
    "feature_names = np.array(feature_names) \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(10), avg_importance[sorted_idx], color='skyblue')\n",
    "plt.yticks(range(10), feature_names[sorted_idx])\n",
    "plt.xlabel('Average Feature Importance')\n",
    "plt.title('Top 10 Feature Importances for XGBoost')\n",
    "plt.gca().invert_yaxis()  # To display the highest importance at the top\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
